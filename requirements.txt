# requirements.txt
selenium==4.16.0
beautifulsoup4==4.12.2
schedule==1.2.1
python-dotenv==1.0.0
webdriver_manager==4.0.1
pandas==2.1.4
requests==2.31.0
lxml==4.9.3

# .env
CHROME_DRIVER_PATH=/usr/local/bin/chromedriver
SCRAPE_INTERVAL=24
LOG_LEVEL=INFO
DATA_DIR=./data
LOG_DIR=./logs

# config.py
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Chrome driver configuration
CHROME_DRIVER_PATH = os.getenv('CHROME_DRIVER_PATH')
CHROME_OPTIONS = [
    '--headless',
    '--no-sandbox',
    '--disable-dev-shm-usage',
    '--disable-gpu',
    '--window-size=1920,1080'
]

# Scraping configuration
SCRAPE_INTERVAL = int(os.getenv('SCRAPE_INTERVAL', 24))
TIMEOUT = 30
RETRY_COUNT = 3
RETRY_DELAY = 5

# Logging configuration
LOG_LEVEL = os.getenv('LOG_LEVEL', 'INFO')
LOG_FORMAT = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
LOG_DIR = os.getenv('LOG_DIR', './logs')
LOG_FILE = os.path.join(LOG_DIR, 'scraper.log')

# Data storage configuration
DATA_DIR = os.getenv('DATA_DIR', './data')
CSV_FILENAME_FORMAT = 'prices_%Y%m%d.csv'

# Target URLs configuration
TARGET_URLS = [
    'https://example.com/products',
    # Add more URLs as needed
]

# .gitignore
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual Environment
venv/
ENV/

# IDEs
.idea/
.vscode/
*.swp
*.swo

# Project specific
data/
logs/
.env
chromedriver
chromedriver.exe

# Misc
.DS_Store
Thumbs.db